{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Datasets:\n",
    "- MNIST\n",
    "- Spambase\n",
    "- 20NG\n",
    "\n",
    "For each, perform 2 classification algorithms:\n",
    "- L2-reg Logistic Regression\n",
    "- Decision Trees\n",
    "\n",
    "\n",
    "allowed to use library for classification. \n",
    "\n",
    "allowed to use library to process data in appropriate formats.\n",
    "\n",
    "You are required to explain/analyze the model trained in terms of features : for each of the 6 runs list the top F=30 features. \n",
    "\n",
    "For the Regression these correspond to the highest-absolute-value F coefficients; \n",
    "\n",
    "for Decision Tree they are the first F splits. In particular for Decision Tree on 20NG, report performance for two tree sizes ( by depths of the tree, or number of leaves, or number of splits )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as torch\n",
    "from sklearn.datasets import _twenty_newsgroups\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='data', download=True, transform=transforms.ToTensor())\n",
    "features = mnist_dataset.data\n",
    "labels = mnist_dataset.targets\n",
    "\n",
    "# Normalize the features\n",
    "features = features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.0257\n",
      "Epoch [2/5], Loss: 1.9207\n",
      "Epoch [3/5], Loss: 1.8654\n",
      "Epoch [4/5], Loss: 1.8299\n",
      "Epoch [5/5], Loss: 1.8045\n",
      "Accuracy of the model on the MNIST test images: 84.15%\n"
     ]
    }
   ],
   "source": [
    "# using pytorch to perform logistic regression:\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "    \n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_dim = 28 * 28  # MNIST images are 28x28 pixels\n",
    "output_dim = 10  # 10 classes for digits 0-9\n",
    "model = LogisticRegression(input_dim, output_dim)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Prepare the data for training\n",
    "features = features.view(-1, input_dim).float()\n",
    "labels = labels.long()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "num_batches = len(features) // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        # Get the batch data\n",
    "        batch_features = features[i * batch_size:(i + 1) * batch_size]\n",
    "        batch_labels = labels[i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(num_batches):\n",
    "        batch_features = features[i * batch_size:(i + 1) * batch_size]\n",
    "        batch_labels = labels[i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "print(f'Accuracy of the model on the MNIST test images: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 features for each class:\n",
      "Class 0: [492 437 460 517 377 351 350 489 490 353 461 409 464 379 432 491 352 381\n",
      " 433 378 405 406 463 434 436 462 407 435 380 408]\n",
      "Class 1: [262 377 381 263 438 407 433 403 402 294 375 493 319 410 382 462 465 295\n",
      " 379 437 409 489 461 323 378 351 322 434 350 406]\n",
      "Class 2: [377 289 152 516 153 125 656 292 316 344 567 569 293 348 321 372 373 374\n",
      " 630 375 657 658 290 320 345 346 317 347 318 319]\n",
      "Class 3: [458 323 545 344 485 289 178 292 515 491 377 462 290 486 514 519 345 262\n",
      " 463 291 461 318 518 544 317 516 488 490 489 517]\n",
      "Class 4: [409 155 294 600 436 597 431 374 465 542 372 373 266 402 429 570 400 184\n",
      " 430 209 464 212 238 239 183 182 401 428 210 211]\n",
      "Class 5: [356 220 435 328 516 489 402 515 219 218 485 354 191 461 353 189 299 375\n",
      " 348 488 355 320 376 326 346 374 325 298 327 347]\n",
      "Class 6: [541 240 214 325 657 486 542 626 659 544 654 514 268 299 297 215 572 213\n",
      " 515 656 296 543 242 298 655 271 269 243 241 270]\n",
      "Class 7: [266 260 240 296 428 156 431 298 350 430 183 403 153 374 429 434 404 377\n",
      " 461 401 375 185 432 184 268 406 433 402 378 405]\n",
      "Class 8: [515 468 455 467 601 404 429 269 372 405 545 658 488 295 267 239 400 573\n",
      " 266 546 410 377 432 376 574 439 460 401 487 438]\n",
      "Class 9: [408 372 153 601 381 152 572 596 437 211 353 571 238 154 568 544 627 600\n",
      " 294 543 599 157 597 542 409 570 156 569 155 598]\n"
     ]
    }
   ],
   "source": [
    "# Analyze model in terms of features, d = top 30 features\n",
    "def analyze_model(model, input_dim):\n",
    "    weights = model.linear.weight.data.numpy()\n",
    "    top_features = np.argsort(np.abs(weights), axis=1)[:, -30:]  # Get top 30 features for each class\n",
    "    return top_features\n",
    "top_features = analyze_model(model, input_dim)\n",
    "\n",
    "print(\"Top 30 features for each class:\")\n",
    "for i in range(output_dim):\n",
    "    print(f\"Class {i}: {top_features[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n",
      "Accuracy of the Decision Tree Classifier on the MNIST dataset: 87.64%\n"
     ]
    }
   ],
   "source": [
    "# Using decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_dataset_train = datasets.MNIST(root='data', train = True, download=True)\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='data', train = False, download=True)\n",
    "print(mnist_dataset_train.data.shape)\n",
    "print(mnist_dataset.data.shape)\n",
    "# Train features, labels\n",
    "features = mnist_dataset_train.data\n",
    "labels = mnist_dataset_train.targets\n",
    "\n",
    "# Test features, labels\n",
    "test_features = mnist_dataset.data\n",
    "test_labels = mnist_dataset.targets\n",
    "\n",
    "# convert to numpy arrays:\n",
    "features = features.numpy()\n",
    "labels = labels.numpy()\n",
    "\n",
    "test_features = test_features.numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "\n",
    "# Normalize the features\n",
    "features = features / 255.0\n",
    "test_features = test_features / 255.0\n",
    "\n",
    "# Reshape the features to 2D array\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "test_features = test_features.reshape(test_features.shape[0], -1)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the Decision Tree Classifier\n",
    "dt_classifier.fit(features, labels)\n",
    "\n",
    "# Predict on the testing set\n",
    "dt_predictions = dt_classifier.predict(test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy = accuracy_score(test_labels, dt_predictions)\n",
    "print(f'Accuracy of the Decision Tree Classifier on the MNIST dataset: {dt_accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spambase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3     4     5     6     7     8     9   ...     48  \\\n",
       "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "         49   50     51     52     53     54   55    56  57  \n",
       "0     0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1     0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2     0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3     0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4     0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "...     ...  ...    ...    ...    ...    ...  ...   ...  ..  \n",
       "4596  0.232  0.0  0.000  0.000  0.000  1.142    3    88   0  \n",
       "4597  0.000  0.0  0.353  0.000  0.000  1.555    4    14   0  \n",
       "4598  0.718  0.0  0.000  0.000  0.000  1.404    6   118   0  \n",
       "4599  0.057  0.0  0.000  0.000  0.000  1.147    5    78   0  \n",
       "4600  0.000  0.0  0.125  0.000  0.000  1.250    5    40   0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase = pd.read_csv('spambase.data', header=None, sep=',')\n",
    "spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "s_labels = spambase.iloc[:, -1]\n",
    "s_features = spambase.iloc[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "s_features = (s_features - s_features.mean()) / s_features.std()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "s_features_train, s_features_test, s_labels_train, s_labels_test = train_test_split(s_features, s_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model on the Spambase dataset: 91.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Using logistic regression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logistic_model.fit(s_features_train, s_labels_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "logistic_predictions = logistic_model.predict(s_features_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "logistic_accuracy = accuracy_score(s_labels_test, logistic_predictions)\n",
    "print(f'Accuracy of the Logistic Regression model on the Spambase dataset: {logistic_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree Classifier on the Spambase dataset: 91.31%\n"
     ]
    }
   ],
   "source": [
    "# Decision tree classifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the Decision Tree Classifier\n",
    "dt_classifier.fit(s_features_train, s_labels_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "dt_predictions = dt_classifier.predict(s_features_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy = accuracy_score(s_labels_test, dt_predictions)\n",
    "print(f'Accuracy of the Decision Tree Classifier on the Spambase dataset: {dt_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_train = _twenty_newsgroups.fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "ng_train_feat = ng_train.data\n",
    "ng_train_labels = ng_train.target\n",
    "\n",
    "ng_test = _twenty_newsgroups.fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "ng_test_feat = ng_test.data\n",
    "ng_test_labels = ng_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit and transform the training features\n",
    "ng_train_features = tfidf_vectorizer.fit_transform(ng_train_feat)\n",
    "\n",
    "# Transform the testing features\n",
    "ng_test_features = tfidf_vectorizer.transform(ng_test_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model on the 20 Newsgroups dataset: 64.83%\n"
     ]
    }
   ],
   "source": [
    "# Using logistic regression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logistic_model.fit(ng_train_features, ng_train_labels)\n",
    "\n",
    "# Predict on the testing set\n",
    "logistic_predictions = logistic_model.predict(ng_test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "logistic_accuracy = accuracy_score(ng_test_labels, logistic_predictions)\n",
    "print(f'Accuracy of the Logistic Regression model on the 20 Newsgroups dataset: {logistic_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: PCA Using library (sklearn compatible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torchvision import datasets, transforms\n",
    "from pca import pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='data', download=True, transform=transforms.ToTensor())\n",
    "features = mnist_dataset.data\n",
    "labels = mnist_dataset.targets\n",
    "\n",
    "# Normalize the features\n",
    "features = features / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
