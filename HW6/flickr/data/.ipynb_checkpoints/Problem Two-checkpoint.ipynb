{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ray/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = list(punctuation) + [\"'s\", \"''\", \"``\",\".\",\"...\"]\n",
    "def pre(dd):   \n",
    "    new = []\n",
    "    #dd = dd.split(\".\")\n",
    "    for item in dd:\n",
    "        item = \" \".join([w for w in word_tokenize(item) if not w in stops])\n",
    "        new.append(item)\n",
    "    return \". \".join(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2 = open('sample_dataset.txt',\"r\")\n",
    "data = f2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "sam_label = []\n",
    "cate = []\n",
    "C = -1\n",
    "prev = \"\"\n",
    "for i in range(len(data)):\n",
    "    a = data[i].replace(\"\\'\",\"\").split(\",\")\n",
    "    sample.append(int(a[0][1:]))\n",
    "    cate.append(a[1][1:])\n",
    "    if a[1][1:]!= prev:\n",
    "        C += 1\n",
    "    sam_label.append(C)\n",
    "    prev = a[1][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('whole_dataset.txt',\"r\")\n",
    "full_data = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = []\n",
    "label = []\n",
    "doc = []\n",
    "for i in range(len(full_data)):\n",
    "    a = full_data[i].replace(\"\\'\",\"\").split(\",\")\n",
    "    ID.append(int(a[0][1:]))\n",
    "    label.append(a[1][1:])\n",
    "    doc.append(pre(a[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 5)\n",
    "vectorizer.fit(doc)\n",
    "duc = vectorizer.transform(doc)\n",
    "#word_con = {k:v for v,k in vectorizer_con.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA and EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.mixture import GaussianMixture as GM\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def problem_two(K,T):\n",
    "    lda = LDA(n_components = T)\n",
    "    lda.fit(duc)\n",
    "    duc_new = lda.transform(duc)\n",
    "    lda_data = duc_new[sample,:]\n",
    "    gm = GM(n_components = K).fit(lda_data)\n",
    "    pred_label = gm.predict_proba(lda_data)\n",
    "    a,b,c = v_measure(pred_label, sam_label, K, 20) \n",
    "    return [K,T,a,b,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 5, 2.02433395997794, 0.8521323558854389, 1.1993886087952594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 2.1389097341794003, 1.2045765078833701, 1.5411939704504392]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 2.465849944024706, 0.8936667286653328, 1.3118839806749008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 50, 2.5853871298770605, 1.30458140035141, 1.7341260918362391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 5, 1.8892956533598118, 1.8127302424376097, 1.8502211838329408]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 10, 1.7074326680298566, 1.5674417489410284, 1.6344451155175752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 20, 2.0664450363145086, 1.5991806970021105, 1.8030313261141384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 50, 2.3669824454129333, 1.7162679850995783, 1.9897756757696767]\n"
     ]
    }
   ],
   "source": [
    "for k in [10,20]:\n",
    "    for t in [5, 10, 20, 50]:\n",
    "        print(problem_two(k,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import itertools, operator\n",
    "import scipy.stats\n",
    "def group_by_label(l):\n",
    "    it = itertools.groupby(l, operator.itemgetter(1))\n",
    "    counts = []\n",
    "    for key, subiter in it:\n",
    "        counts.append(sum(item[0] for item in subiter))\n",
    "    return counts\n",
    "\n",
    "def compute_homogeneity(preds, labels):\n",
    "    cluster_label_counts = []\n",
    "    for pred in preds.transpose():\n",
    "        cluster_label_counts.append(group_by_label([(p,label) for p,label in zip(pred,labels)]))\n",
    "    \n",
    "    entropys = []\n",
    "    for cluster_label_count in cluster_label_counts:\n",
    "        entropys.append(scipy.stats.entropy(cluster_label_count))\n",
    "         \n",
    "    return np.mean(entropys)\n",
    "\n",
    "def compute_completeness(preds, labels, num_clusters, num_labels):\n",
    "    label_cluster_counts = {label:np.zeros(num_clusters) for label in range(num_labels)}\n",
    "    \n",
    "    for pred, label in zip(preds, labels):\n",
    "        label_cluster_counts[label] = np.sum([label_cluster_counts[label], pred], axis=0)\n",
    "    \n",
    "    entropys = []\n",
    "    for label_cluster_count in label_cluster_counts.values():\n",
    "        entropys.append(scipy.stats.entropy(label_cluster_count))\n",
    "          \n",
    "    return np.mean(entropys)\n",
    "\n",
    "\n",
    "def v_measure(preds, labels, num_clusters, num_labels):\n",
    "    if len(labels) == 0:\n",
    "        return 1.0, 1.0, 1.0\n",
    "      \n",
    "    homogeneity = compute_homogeneity(preds, labels)\n",
    "    completeness = compute_completeness(preds, labels, num_clusters, num_labels)\n",
    "    \n",
    "    if homogeneity==0.0 and completeness==0.0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    v_measure_score = (2.0 * homogeneity * completeness /\n",
    "                   (homogeneity + completeness))\n",
    "      \n",
    "    return homogeneity, completeness, v_measure_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lda_f = LDA(n_components = 20)\n",
    "lda_f.fit(duc)\n",
    "final = lda_f.transform(duc)\n",
    "lda_final = final[sample,:]\n",
    "gm_f = GM(n_components = 10).fit(lda_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gm_f.predict(lda_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] in dic:\n",
    "        dic[predicted[i]].append(i)\n",
    "    else:\n",
    "        dic[predicted[i]] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: ('rec.sport.hockey', 'sci.crypt', 'talk.politics.guns', 'rec.sport.baseball', 'talk.politics.misc')\n",
      "Cluster 2: ('comp.windows.x', 'misc.forsale', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt')\n",
      "Cluster 3: ('rec.sport.hockey', 'talk.politics.mideast', 'rec.sport.baseball', 'misc.forsale', 'sci.electronics')\n",
      "Cluster 4: ('rec.sport.hockey', 'sci.crypt', 'rec.motorcycles', 'rec.sport.baseball', 'talk.politics.guns')\n",
      "Cluster 5: ('rec.sport.baseball', 'misc.forsale', 'rec.sport.hockey', 'alt.atheism', 'sci.med')\n",
      "Cluster 6: ('comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'comp.windows.x', 'comp.sys.ibm.pc.hardware')\n",
      "Cluster 7: ('rec.sport.hockey', 'rec.motorcycles', 'rec.sport.baseball', 'talk.politics.misc', 'talk.politics.guns')\n",
      "Cluster 8: ('rec.sport.hockey', 'talk.politics.guns', 'rec.autos', 'sci.crypt', 'comp.os.ms-windows.misc')\n",
      "Cluster 9: ('misc.forsale', 'sci.med', 'rec.sport.baseball', 'rec.autos', 'rec.sport.hockey')\n",
      "Cluster 10: ('talk.politics.mideast', 'rec.motorcycles', 'comp.windows.x', 'talk.politics.guns', 'talk.politics.misc')\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cate = np.array(cate)\n",
    "best = 0\n",
    "for i in range(len(dic.keys())):\n",
    "    a = Counter(cate[np.array(dic[i])]).most_common()[:5]\n",
    "    if a[0][1]/len(dic[i]) > best:\n",
    "        best = i\n",
    "    print(\"Cluster %s: %s\"%(i+1, list(zip(*a))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest Cluster is 2 Cluster\n"
     ]
    }
   ],
   "source": [
    "print(\"The biggest Cluster is %s Cluster\"% (best+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
