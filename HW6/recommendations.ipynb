{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2bcd3d",
   "metadata": {},
   "source": [
    "## Implement a movie recommendation system and run it on the movie lens dataset \n",
    "\n",
    "(train vs test)\n",
    "\n",
    "Measure performance on test set using RMSE (Root mean squared deviation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1abbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f332b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80000 entries, 0 to 79999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   user       80000 non-null  category\n",
      " 1   item       80000 non-null  category\n",
      " 2   rating     80000 non-null  int64   \n",
      " 3   timestamp  80000 non-null  int64   \n",
      "dtypes: category(2), int64(2)\n",
      "memory usage: 1.6 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   user       20000 non-null  category\n",
      " 1   item       20000 non-null  category\n",
      " 2   rating     20000 non-null  int64   \n",
      " 3   timestamp  20000 non-null  int64   \n",
      "dtypes: category(2), int64(2)\n",
      "memory usage: 473.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# first, generate train and test sets of data:\n",
    "filepath = 'ml-100k/u'\n",
    "#pd.read_csv(filepath, sep='\\t', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
    "u = ['1', '2', '3', '4', '5']\n",
    "    # base = train\n",
    "    # test = test\n",
    "for i in u:\n",
    "    train = pd.read_csv(f'{filepath}{i}.base', sep='\\t', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
    "    test = pd.read_csv(f'{filepath}{i}.test', sep='\\t', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
    "    train['user'] = train['user'].astype('category')\n",
    "    test['user'] = test['user'].astype('category')\n",
    "    train['item'] = train['item'].astype('category')\n",
    "    test['item'] = test['item'].astype('category')\n",
    "\n",
    "# observe data:\n",
    "# print(train.head())\n",
    "# print(test.head())\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dced4652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 943\n",
      "Number of unique movies: 1650\n"
     ]
    }
   ],
   "source": [
    "# unique users and items:\n",
    "n_users = train['user'].nunique()\n",
    "print(f'Number of unique users: {n_users}')\n",
    "\n",
    "n_items = train['item'].nunique()\n",
    "print(f'Number of unique movies: {n_items}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af703b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between user 1 and user 2: 15.207373271889399\n"
     ]
    }
   ],
   "source": [
    "# First, required to compute a user-user similarity based on ratings and movies in common. \n",
    "\n",
    "# dot product, average over common ratings\n",
    "    # Pearsons:\n",
    "def user_similarity(train, user1, user2):\n",
    "    # get ratings for both users\n",
    "    user1_ratings = train[train['user'] == user1]\n",
    "    user2_ratings = train[train['user'] == user2]\n",
    "\n",
    "    # merge ratings on item\n",
    "    merged_ratings = pd.merge(user1_ratings, user2_ratings, on='item', suffixes=('_user1', '_user2'))\n",
    "\n",
    "    # calculate similarity based on common ratings\n",
    "    if len(merged_ratings) == 0:\n",
    "        return 0  # no common items\n",
    "\n",
    "    # calculate the dot product of the ratings\n",
    "    dot_product = np.dot(merged_ratings['rating_user1'], merged_ratings['rating_user2'])\n",
    "\n",
    "    # calculate the average rating for each user\n",
    "    avg_user1 = merged_ratings['rating_user1'].mean()\n",
    "    avg_user2 = merged_ratings['rating_user2'].mean()\n",
    "\n",
    "    # calculate the similarity score\n",
    "    similarity_score = dot_product / (avg_user1 * avg_user2)\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Example usage:\n",
    "user1 = 1\n",
    "user2 = 2\n",
    "similarity = user_similarity(train, user1, user2)\n",
    "print(f'Similarity between user {user1} and user {user2}: {similarity}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec647293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 1 on item 1: 3.8850903599452957\n"
     ]
    }
   ],
   "source": [
    "# Second, make rating predictions on the test set following the KNN idea: \n",
    "# a prediction (user, movie) is the weighted average of other users' rating for the movie, weighted by user-similarity to the given user. \n",
    "def predict_rating(train, test, user1, item):\n",
    "    # get ratings for the item from all users\n",
    "    item_ratings = train[train['item'] == item]\n",
    "\n",
    "    # calculate similarity for each user who rated the item\n",
    "    similarities = []\n",
    "    for user2 in item_ratings['user'].unique():\n",
    "        if user2 != user1:\n",
    "            similarity = user_similarity(train, user1, user2)\n",
    "            similarities.append((user2, similarity))\n",
    "\n",
    "    # calculate the weighted average rating\n",
    "    if len(similarities) == 0:\n",
    "        return 0  # no similar users\n",
    "\n",
    "    weighted_sum = 0\n",
    "    total_weight = 0\n",
    "    for user2, similarity in similarities:\n",
    "        rating = item_ratings[item_ratings['user'] == user2]['rating'].values[0]\n",
    "        weighted_sum += rating * similarity\n",
    "        total_weight += abs(similarity)\n",
    "\n",
    "    predicted_rating = weighted_sum / total_weight\n",
    "\n",
    "    return predicted_rating\n",
    "\n",
    "# Example usage:\n",
    "user1 = 1\n",
    "item = 1\n",
    "predicted_rating = predict_rating(train, test, user1, item)\n",
    "print(f'Predicted rating for user {user1} on item {item}: {predicted_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706f571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
