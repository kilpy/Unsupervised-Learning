{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL tSNE on MNIST dataset: \n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\koola\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\koola\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.9.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (2.2.1)\n",
      "Collecting dm-tree (from tensorflow-datasets)\n",
      "  Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting etils>=1.9.1 (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading etils-1.12.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting immutabledict (from tensorflow-datasets)\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (1.26.4)\n",
      "Collecting promise (from tensorflow-datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (5.29.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (6.1.1)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (19.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (2.32.3)\n",
      "Collecting simple_parsing (from tensorflow-datasets)\n",
      "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets)\n",
      "  Downloading tensorflow_metadata-1.17.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (3.0.1)\n",
      "Collecting toml (from tensorflow-datasets)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-datasets) (1.17.2)\n",
      "Collecting einops (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2024.12.0)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.12.2)\n",
      "Collecting zipp (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2025.1.31)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple_parsing->tensorflow-datasets)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow-datasets)\n",
      "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->tensorflow-datasets) (0.4.6)\n",
      "Downloading tensorflow_datasets-4.9.8-py3-none-any.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.8/5.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.4/5.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.1/5.3 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.7/5.3 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.5/5.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.2/5.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.3/5.3 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading etils-1.12.2-py3-none-any.whl (167 kB)\n",
      "Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "Downloading tensorflow_metadata-1.17.0-py3-none-any.whl (29 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21613 sha256=f6bc875997adcaacafe6c3b5c836f944d2f15548b8cc82065da6a1c81c065a6d\n",
      "  Stored in directory: c:\\users\\koola\\appdata\\local\\pip\\cache\\wheels\\e7\\e6\\28\\864bdfee5339dbd6ddcb5a186286a8e217648ec198bdf0097d\n",
      "Successfully built promise\n",
      "Installing collected packages: zipp, toml, promise, importlib_resources, immutabledict, googleapis-common-protos, etils, einops, docstring-parser, dm-tree, tensorflow-metadata, simple_parsing, tensorflow-datasets\n",
      "Successfully installed dm-tree-0.1.9 docstring-parser-0.16 einops-0.8.1 etils-1.12.2 googleapis-common-protos-1.69.2 immutabledict-4.2.1 importlib_resources-6.5.2 promise-2.3 simple_parsing-0.1.7 tensorflow-datasets-4.9.8 tensorflow-metadata-1.17.0 toml-0.10.2 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# mnist = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "# import tensor\n",
    "%pip install tensorflow\n",
    "import tensorflow as tf\n",
    "%pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtfds\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder C:\\Users\\koola\\tensorflow_datasets\\mnist\\3.0.1 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\koola\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cf19882ac4495eb9c57fa0dad7e2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcaaaa0284e475ab400589256f3de2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a5fea4366c45d9bd49fb7ae78832bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f76d23b91de4144a8e89e8bee909560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5576f21899b4bca9ba883419a2c2e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072d33c9b5cb4468b45836ae92e7c69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\koola\\tensorflow_datasets\\mnist\\incomplete.YM9TDL_3.0.1\\mnist-train.tfrecord*...:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pseudocode: \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mnist \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_supervised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# load mnist dataset from tensorflow datasets\u001b[39;00m\n\u001b[0;32m      3\u001b[0m mnist \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m) \u001b[38;5;66;03m# shuffle the dataset to get random samples\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# load mnist into matrix X\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\load.py:666\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs, file_format)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# fmt: skip\u001b[39;00m\n\u001b[0;32m    660\u001b[0m dbuilder \u001b[38;5;241m=\u001b[39m _fetch_builder(\n\u001b[0;32m    661\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    662\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m    663\u001b[0m     builder_kwargs\u001b[38;5;241m=\u001b[39mbuilder_kwargs,\n\u001b[0;32m    664\u001b[0m     try_gcs\u001b[38;5;241m=\u001b[39mtry_gcs,\n\u001b[0;32m    665\u001b[0m )\n\u001b[1;32m--> 666\u001b[0m \u001b[43m_download_and_prepare_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    669\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\load.py:518\u001b[0m, in \u001b[0;36m_download_and_prepare_builder\u001b[1;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m    517\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m--> 518\u001b[0m   \u001b[43mdbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:763\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config, file_format, permissions)\u001b[0m\n\u001b[0;32m    761\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mread_from_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir)\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 763\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    769\u001b[0m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    770\u001b[0m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    771\u001b[0m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    772\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdownload_size \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownloaded_size\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1808\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_config\u001b[38;5;241m.\u001b[39mmax_examples_per_split \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1806\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1808\u001b[0m split_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;66;03m# Update the info object with the splits.\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m splits_lib\u001b[38;5;241m.\u001b[39mSplitDict(split_infos)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1782\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._generate_splits\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1775\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m split_name, generator \u001b[38;5;129;01min\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m   1776\u001b[0m       split_generators\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1777\u001b[0m       desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating splits...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1778\u001b[0m       unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m splits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1779\u001b[0m       leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1780\u001b[0m   ):\n\u001b[0;32m   1781\u001b[0m     filename_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_filename_template(split_name\u001b[38;5;241m=\u001b[39msplit_name)\n\u001b[1;32m-> 1782\u001b[0m     future \u001b[38;5;241m=\u001b[39m \u001b[43msplit_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_split_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_shuffling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_shuffling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnondeterministic_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnondeterministic_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m     split_info_futures\u001b[38;5;241m.\u001b[39mappend(future)\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;66;03m# Process the result of the beam pipeline.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\split_builder.py:447\u001b[0m, in \u001b[0;36mSplitBuilder.submit_split_generation\u001b[1;34m(self, split_name, generator, filename_template, disable_shuffling, nondeterministic_order)\u001b[0m\n\u001b[0;32m    442\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`nondeterministic_order` is set to True for a dataset that does\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not use beam. Setting `disable_shuffling` to True.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    445\u001b[0m     )\n\u001b[0;32m    446\u001b[0m     build_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_shuffling\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuild_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Otherwise, beam required\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   unknown_generator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    450\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid split generator value for split `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    451\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected generator or apache_beam object. Got: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    452\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(generator)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    453\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\split_builder.py:527\u001b[0m, in \u001b[0;36mSplitBuilder._build_from_generator\u001b[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[0m\n\u001b[0;32m    525\u001b[0m   writer\u001b[38;5;241m.\u001b[39mwrite(key, example)\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 527\u001b[0m   shard_lengths, total_size \u001b[38;5;241m=\u001b[39m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    529\u001b[0m   utils\u001b[38;5;241m.\u001b[39mreraise(\n\u001b[0;32m    530\u001b[0m       e, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to finalize writing of split \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    531\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\writer.py:398\u001b[0m, in \u001b[0;36mWriter.finalize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_spec \u001b[38;5;129;01min\u001b[39;00m shard_specs:\n\u001b[0;32m    395\u001b[0m   iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mislice(\n\u001b[0;32m    396\u001b[0m       examples_generator, \u001b[38;5;241m0\u001b[39m, shard_spec\u001b[38;5;241m.\u001b[39mexamples_number\n\u001b[0;32m    397\u001b[0m   )\n\u001b[1;32m--> 398\u001b[0m   record_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_example_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m   \u001b[38;5;66;03m# No shard keys returned (e.g: TFRecord format), index cannot be\u001b[39;00m\n\u001b[0;32m    401\u001b[0m   \u001b[38;5;66;03m# created.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m record_keys:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\writer.py:194\u001b[0m, in \u001b[0;36mExampleWriter.write\u001b[1;34m(self, path, examples)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write examples from iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    193\u001b[0m adapter \u001b[38;5;241m=\u001b[39m file_adapters\u001b[38;5;241m.\u001b[39mADAPTER_FOR_FORMAT[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_format]\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_datasets\\core\\file_adapters.py:223\u001b[0m, in \u001b[0;36mTfRecordFileAdapter.write_examples\u001b[1;34m(cls, path, iterator)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrite_examples\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    211\u001b[0m     path: epath\u001b[38;5;241m.\u001b[39mPathLike,\n\u001b[0;32m    212\u001b[0m     iterator: Iterable[type_utils\u001b[38;5;241m.\u001b[39mKeySerializedExample],\n\u001b[0;32m    213\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExamplePositions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Write examples from given iterator in given path.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFRecordWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, serialized_example \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    225\u001b[0m       writer\u001b[38;5;241m.\u001b[39mwrite(serialized_example)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\lib\\io\\tf_record.py:294\u001b[0m, in \u001b[0;36mTFRecordWriter.__init__\u001b[1;34m(self, path, options)\u001b[0m\n\u001b[0;32m    291\u001b[0m   options \u001b[38;5;241m=\u001b[39m TFRecordOptions(compression_type\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFRecordWriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_record_writer_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pseudocode: \n",
    "mnist = tfds.load('mnist', split='train', as_supervised=False) # load mnist dataset from tensorflow datasets\n",
    "mnist = mnist.shuffle(buffer_size=10000) # shuffle the dataset to get random samples\n",
    "# load mnist into matrix X\n",
    "x = mnist.data.numpy().reshape(-1, 28*28)\n",
    "x = x.astype(np.float64)\n",
    "y = mnist.targets.numpy()\n",
    "\n",
    "# sample n images \n",
    "n = 4000\n",
    "np.random.seed(0)\n",
    "idx = np.random.choice(len(x), n)\n",
    "x = x[idx]\n",
    "print(x.shape)\n",
    "\n",
    "# print(x)\n",
    "# prep X: 0-1 range;\n",
    "# x = x / 255\n",
    "# x = x - x.mean(axis=0)\n",
    "# print(np.mean(x, axis=0))\n",
    "# print(np.mean(x, axis=1))\n",
    "xx = x - np.min(x)\n",
    "xx = xx / np.max(xx) # min-max normalization\n",
    "xx = xx - np.mean(xx,axis=0)\n",
    "# print(xx)\n",
    "# run PCA to 50 dimensions\n",
    "x = xx\n",
    "pca = PCA(n_components=50)\n",
    "x_pca = pca.fit_transform(x)\n",
    "\n",
    "print(x_pca.shape)\n",
    "# compute pairwise distance matrix D\n",
    "\n",
    "D = cdist(x_pca, x_pca)\n",
    "\n",
    "# compute similarities p_ij for each row i:\n",
    "P = np.zeros([n, n])\n",
    "for i in range(n):\n",
    "    beta = 0.6\n",
    "    D_i = D[i, :]\n",
    "    P_i = np.zeros(n)\n",
    "    # binary like search for beta(i)\n",
    "    trials = 0\n",
    "    hdiff = 1\n",
    "    betamin = -np.inf\n",
    "    betamax = np.inf\n",
    "    while(np.abs(hdiff) > 1e-5 and trials < 50):\n",
    "        P_i = np.exp(-D_i * beta)\n",
    "        P_i_sum = np.sum(P_i)\n",
    "        # betac = (betamin + betamax) / 2\n",
    "        # h = np.sum(np.exp(-D_i * P_i_sum))\n",
    "        h = np.log(P_i_sum) + beta * (np.dot(D_i, P_i)/P_i_sum)\n",
    "        hdiff = h - np.log2(30)\n",
    "        if hdiff > 0:\n",
    "            # betac = (betamin + betamax) / 2\n",
    "            betamin = beta\n",
    "            if(betamax == np.inf):\n",
    "                beta = beta * 2\n",
    "            else:\n",
    "                beta = (beta + betamax) / 2\n",
    "        else:\n",
    "            # betac = (betamin + betamax) / 2\n",
    "            betamax = beta\n",
    "            if(betamin == -np.inf):\n",
    "                beta = beta / 2\n",
    "            else:\n",
    "                beta = (beta + betamin) / 2\n",
    "    trials += 1\n",
    "    # beta = betac\n",
    "    P[i, :] = P_i  \n",
    "\n",
    "#make sure P is correct\n",
    "for i in range(n):\n",
    "    P[i,i] = 1e-5\n",
    "\n",
    "P = (P + P.T) / 2 # Symmetric\n",
    "P = P / np.sum(P) # Normalized\n",
    "# print(P[1,0])\n",
    "\n",
    "print(P.shape)\n",
    "constKL = np.sum(P * np.log(P))\n",
    "print(\"ConstKL: \", constKL)\n",
    "# initialize tSNE\n",
    "max_iter = 451\n",
    "epsilon = 500\n",
    "min_gain = 0.01\n",
    "Y = np.random.randn(n, 2)\n",
    "# dY = np.zeros((n, 2))\n",
    "iY = np.zeros([n, 2])\n",
    "gains = np.ones([n, 2])\n",
    "\n",
    "# run tSNE\n",
    "for i in tqdm(range(max_iter)):\n",
    "    # compute Q\n",
    "    Y2 = Y**2\n",
    "    sum_Y2 = np.sum(Y2, axis=1, keepdims=True)\n",
    "    Q = np.zeros([n, n])\n",
    "    \n",
    "    dist = 1.0 / (sum_Y2 - 2 * np.dot(Y, Y.T) + sum_Y2.T)\n",
    "    # Q = 1 / (1 + dist)\n",
    "    np.fill_diagonal(dist, 1e-5)\n",
    "    Q = dist / np.sum(dist)\n",
    "    # Q = np.maximum(Q, 1e-12)\n",
    "    \n",
    "    # compute dY\n",
    "    PQ = (P - Q) * dist\n",
    "\n",
    "    # for k in range(n):\n",
    "    #     dY[k] = np.sum(np.tile(PQ[:, k] * Q[:, k], (2, 1)).T * (Y[k] - Y), axis=0)\n",
    "    dY = 4 * np.dot(np.diag(np.sum(PQ, axis=1)) - PQ, Y)\n",
    "    \n",
    "    # perform the update\n",
    "    # if i == 0:\n",
    "    #     gains = np.sign(dY) != np.sign(iY)\n",
    "    # else:\n",
    "    #     gains[gains > 20] = 20\n",
    "    #     gains[gains < 0.01] = 0.01\n",
    "\n",
    "    # iY = epsilon * iY - 0.2 * gains * dY\n",
    "    iY = -epsilon * dY\n",
    "    Y = Y + iY\n",
    "    # Y = Y - np.tile(np.mean(Y, axis=0), (n, 1))\n",
    "    Y = Y - np.mean(Y, axis=0)\n",
    "    \n",
    "    # compute the KL divergence\n",
    "    if i % 50 == 0:\n",
    "        C = constKL - np.sum(P * np.log(Q))\n",
    "        print(\"Iteration\", i, \"KL divergence is\", C)\n",
    "        plt.scatter(Y[:, 0], Y[:, 1], c=y[idx], cmap='tab10')\n",
    "        plt.xlim(-50, 50)\n",
    "        plt.ylim(-50, 50)\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
