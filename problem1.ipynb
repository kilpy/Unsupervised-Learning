{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM 1: Aminer : basic dataset analysis\n",
    "This is a large dataset (about 2 million publications – it takes about a minute just to parse!). \n",
    "While your notebook must successfully work on the entire dataset, you may find it useful to work on a subset while getting your code to work.\n",
    "\n",
    "A. Compute the number of distinct authors, publication venues, publications, and citations/references\n",
    "B. Are these numbers likely to be accurate? As an example look up all the publications venue names associated with the conference “Principles and Practice of Knowledge Discovery in Databases” – what do you notice?\n",
    "C. For each author, construct the list of publications. Plot a histogram of the number of publications per author (use a logarithmic scale on the y axis)\n",
    "D. Calculate the mean and standard deviation of the number of publications per author. Also calculate the Q1 (1st quartile14), Q2 (2nd quartile, or median) and Q3 (3rd quartile) values. Compare the median to the mean and explain the difference between the two values based on the standard deviation and the 1st and 3rd quartiles.\n",
    "E. Now plot a histogram of the number of publications per venue, as well as calculate the mean, standard deviation, median, Q1, and Q3 values. What is the venue with the largest number of publications in the dataset?\n",
    "F. Plot a histogram of the number of references (number of publications a publication refers to) and citations (number of publications referring to a publication) per publication. What is the publication with the largest number of references? What is the publication with the largest number of citations? Do these make sense?\n",
    "G. Calculate the so called “impact” factor for each venue. To do so, calculate the total number of citations for the publications in the venue, and then divide this number by the number of publications for the venue. Plot a histogram of the results\n",
    "H. What is the venue with the highest apparent impact factor? Do you believe this number?(http://mdanderson.libanswers.com/faq/26159)\n",
    "I. Now repeat the calculation from item G, but restrict the calculation to venues with at least 10 publications. How does your histogram change? List the citation counts for all publications from the venue with the highest impact factor. How does the impact factor (mean number of citations) compare to the median number of citations?\n",
    "J. Finally, construct a list of publications for each publication year. Use this list to plot the average number of references and average number of citations per publication as a function of time. Explain the differences you see in the trends.\n",
    "\n",
    "https://en.wikipedia.org/wiki/IPython#Notebook\n",
    "https://aminer.org\n",
    "https://en.wikipedia.org/wiki/ECML_PKDD\n",
    "https://en.wikipedia.org/wiki/Quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\koola\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. Compute the number of distinct authors, publication venues, publications, and citations/references\n",
    "#df = pd.read_csv('acm.txt', header=None)\n",
    "\n",
    "#df.to_csv('acm.csv', index=False)\n",
    "\n",
    "#store in dictionary: \n",
    "data = {'Index': [], 'Title': [], 'Authors': [], 'Publication Venue': [], 'Citation/Reference': []}\n",
    "\n",
    "\n",
    "\n",
    "# approach 1: \n",
    "    # list of keys\n",
    "        # if found, remove/add to list\n",
    "        # after processessing entry, insert null for keys not found\n",
    "\n",
    "# approach 2:\n",
    "    # dictionary\n",
    "        # variable for \"index\"?\n",
    "        \n",
    "\n",
    "#read in from file:\n",
    "required_keys = [\"Index\", \"Title\", 'Authors', 'Publication Venue', 'Citation/Reference']\n",
    "citations = []\n",
    "with open('acm.txt', 'r', encoding = 'utf-8') as f:\n",
    "\n",
    "    for line in f:\n",
    "        # remove the '#' character:\n",
    "        line = line.replace('#', '')\n",
    "\n",
    "        line = line.split('\\n')\n",
    "        \n",
    "        # determine when a new entry ends:\n",
    "        if line[0] == '' or line[0] == EOFError:\n",
    "            if len(citations) > 0:\n",
    "                citations = ' '.join(citations)\n",
    "                data['Citation/Reference'].append(citations)\n",
    "                required_keys.remove('Citation/Reference')\n",
    "\n",
    "            # end of previous entry, so process the entry by setting missing values to none\n",
    "            for key in required_keys:\n",
    "                data[key].append(None)\n",
    "            \n",
    "            # reset keys for next iteration\n",
    "            required_keys = [\"Index\", \"Title\", 'Authors', 'Publication Venue', 'Citation/Reference']\n",
    "            citations = []\n",
    "        else: # we are in the middle of an entry\n",
    "            \n",
    "            # determine attribute type:\n",
    "            # title\n",
    "            if line[0][0] == '*':\n",
    "                line = line[0].replace('*', '')\n",
    "                data['Title'].append(line)\n",
    "                # mark the key as seen\n",
    "                required_keys.remove('Title')\n",
    "            # author\n",
    "            elif line[0][0] == '@':\n",
    "                line = line[0].replace('@', '')\n",
    "                data['Authors'].append(line)\n",
    "                # mark the key as seen\n",
    "                required_keys.remove('Authors')\n",
    "            # publication venue\n",
    "            elif line[0][0] == 'c':\n",
    "                line = line[0].replace('c', '')\n",
    "                data['Publication Venue'].append(line)\n",
    "                # mark the key as seen\n",
    "                required_keys.remove('Publication Venue')\n",
    "            # index\n",
    "            elif line[0][0] == 'i':\n",
    "                line = line[0].replace('index', '')\n",
    "                data['Index'].append(line)\n",
    "                # mark the key as seen\n",
    "                required_keys.remove('Index')\n",
    "            # citation/reference\n",
    "            elif line[0][0] == '%':\n",
    "                line = line[0].replace('%', '')\n",
    "                # dealing with multiple citations:\n",
    "                citations.append(line)\n",
    "            # else we have time or abstract (not needed)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "# by 1 error:\n",
    "if len(citations) > 0:\n",
    "    citations = ' '.join(citations)\n",
    "    data['Citation/Reference'].append(citations)\n",
    "\n",
    "\n",
    "# output: a full dictionary that is value-consistent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      2\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
